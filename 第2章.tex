\documentclass[pdflatex,ja=standard]{bxjsarticle}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[japanese]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{latexsym}
\usepackage{pxjahyper}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{amssymb}


\title{『多変量解析入門』　演習問題　解答　第2章}
\author{Taro Masuda \\ Twitter ID: @ml\_taro}

\begin{document}
\maketitle

\section{はじめに}
このPDFでは，小西貞則 著『多変量解析入門　線形から非線形へ』(岩波書店，2010)の解答を記していきます．
公式なものではなくあくまで個人として公開しているため，誤りがある可能性があります．正確性についての保証はできない旨，予めご了承ください．

なお，著作権へ配慮し，問題文については割愛させていただきます．

誤りを見つけた場合は，上記twitter ID \href{https://twitter.com/ml_taro}{@ml\_taro} までご連絡いただくか，直接PRを飛ばして頂くか，メール taro.masuda.jp あっとまーく gmail.com までご連絡ください．

\section{第2章}

\subsection{問2.1}

\begin{proof}
\begin{equation}
\frac{\partial S(\beta_{0}, \beta_{1})}{\partial \beta_{0}} =  \sum_{i=1}^{n} 2 \{ y_i - ( \beta_0 + \beta_1 x_i )  \}  (-1) .
\end{equation}
これを0とおくと
\begin{equation}
\sum_{i=1}^{n} y_i = n \beta_0 + \beta_1 \sum_{i=1}^{n} x_i. 
\end{equation}
同様に$\beta_1$ でも微分して0とおくと
\begin{equation}
\frac{\partial S(\beta_{0}, \beta_{1})}{\partial \beta_{1}} =  \sum_{i=1}^{n} 2 \{ y_i - ( \beta_0 + \beta_1 x_i )  \} (-x_i) = 0
\iff \sum_{i=1}^{n} x_i y_i =  \beta_0 \sum_{i=1}^{n} x_i + \beta_1 \sum_{i=1}^{n} x_i^2.
\end{equation}
\end{proof}

\subsection{問2.2}
誤差の2乗和を最小化したいので，
\begin{equation}
S(\bm{\beta}) = \bm{\varepsilon}^{\mathsf{T}} \bm{\varepsilon} = (\bm{y} - X \bm{\beta})^{\mathsf{T}} (\bm{y} - X \bm{\beta})
\end{equation}
を$\bm{\beta}$について微分して
\begin{equation}
- 2 X^{\mathsf{T}} \bm{y} + 2 X^{\mathsf{T}}X \bm{\beta} = \bm{0}. 
\end{equation}
これを解いて，　$\hat{\bm{\beta}}_{\rm{LMS}} = (X^{\mathsf{T}} X)^{-1} X^{\mathsf{T}} \bm{y}$　を得る．

\subsection{問2.3}
尤度関数は
\begin{equation}
L(\bm{\beta}, \sigma^2) = \frac{1}{(2 \pi \sigma^2)^{n/2}} \exp \left[ -\frac{1}{2 \sigma^2} (\bm{y} - X \bm{\beta})^{\mathsf{T}} (\bm{y} - X \bm{\beta}) \right]
\end{equation}
となり，これの対数をとると
\begin{equation}
\log L(\bm{\beta}, \sigma^2) = - \frac{n}{2} \log (2 \pi \sigma^2)  -\frac{1}{2 \sigma^2} (\bm{y} - X \bm{\beta})^{\mathsf{T}} (\bm{y} - X \bm{\beta}) .
\end{equation}
これを$\bm{\beta}$について微分すると
\begin{equation}
- 2 X^{\mathsf{T}} \bm{y} + 2 X^{\mathsf{T}}X \bm{\beta} = \bm{0}
\iff \hat{\bm{\beta}}_{\rm{ML}} = (X^{\mathsf{T}} X)^{-1} X^{\mathsf{T}} \bm{y}.
\end{equation}
同様に，$\sigma^2$について微分すると
\begin{equation}
- \frac{n}{2} \frac{1}{2 \pi \sigma^2}  2 \pi + \frac{1}{2 (\sigma^2)^2} (\bm{y} - X \bm{\beta})^{\mathsf{T}} (\bm{y} - X \bm{\beta})
\iff \hat{\sigma}^2 = \frac{1}{n} (\bm{y} - X \bm{\beta})^{\mathsf{T}} (\bm{y} - X \bm{\beta}).
\end{equation}

\subsection{問2.4}
問2.2, 問2.3より $\hat{\bm{\beta}}_{\rm{LMS}} = \hat{\bm{\beta}}_{\rm{ML}}$. 

\subsection{問2.5}
\begin{proof}
\begin{equation}
\frac{\partial (\bm{c}^{\mathsf{T}} \bm{\beta})}{\partial \bm{\beta}} = \frac{\partial }{\partial \bm{\beta}} \left( \sum_{i=1}^{p+1} c_i \beta_i \right).
\end{equation}
これを$j$番目の成分ごとに表示すると
\begin{equation}
\frac{\partial }{\partial \beta_j} \left( \sum_{i=1}^{p+1} c_i \beta_i \right) = c_j.
\end{equation}
\begin{equation}
\therefore \frac{\partial (\bm{c}^{\mathsf{T}} \bm{\beta})}{\partial \bm{\beta}} = \bm{c}.
\end{equation}
\end{proof}

\begin{proof}
\begin{equation}
\bm{\beta}^{\mathsf{T}} A \bm{\beta} =  \sum_{i=1}^{p+1} \beta_i \sum_{k=1}^{p+1} a_{ik} \beta_k
\end{equation}
と表せるので，
\begin{equation}
\frac{\partial}{\partial \beta_l} \left( \bm{\beta}^{\mathsf{T}} A \bm{\beta} \right) = \sum_{k \neq l} a_{lk} \beta_k + \sum_{i \neq l} a_{il} \beta_i + 2 a_{ll} \beta_l
\end{equation}
\begin{equation}
= \sum_{k=1}^{p+1} (a_{lk} + a_{kl}) \beta_k
\end{equation}
これは$(A + A^{\mathsf{T}}) \bm{\beta}$の第$l$成分に等しい．
\end{proof}

\subsection{問2.6}
\begin{proof}
\begin{equation}
E[\bm{Z}] = E[\bm{c} + A \bm{Y}] = E[\bm{c}] + E[A\bm{Y}] = \bm{c} + A E[\bm{Y}].
\end{equation}
\end{proof}

\begin{proof}
\begin{equation}
E[(\bm{Z} - E[\bm{Z}])(\bm{Z} - E[\bm{Z}])^{\mathsf{T}}]] = E[(\bm{c} + A\bm{Y})(\bm{c} + A\bm{Y})^{\mathsf{T}}] - (\bm{c} + A E[\bm{Y}])(\bm{c} + A E[\bm{Y}])^{\mathsf{T}}
\end{equation}
\begin{equation}
= \bm{c} \bm{c}^{\mathsf{T}} + 2 \bm{c} E[\bm{Y}^{\mathsf{T}}] A^{\mathsf{T}} + A E[ \bm{Y} \bm{Y}^{\mathsf{T}}] A^{\mathsf{T}} - \bm{c} \bm{c}^{\mathsf{T}} - 2 \bm{c} E[\bm{Y}^{\mathsf{T}}] A^{\mathsf{T}} -  A E[ \bm{Y}] E[ \bm{Y}^{\mathsf{T}}] A^{\mathsf{T}} 
\end{equation}
\begin{equation}
= A(E[\bm{Y}\bm{Y}^{\mathsf{T}}] - E[\bm{Y}]E[\bm{Y}^{\mathsf{T}}])A^{\mathsf{T}} = A {\rm cov} (\bm{Y}) A^{\mathsf{T}}.
\end{equation}

\end{proof}

\subsection{問2.7}
\begin{proof}
\begin{equation}
P^2 = X (X^{\mathsf{T}} X )^{-1} X^{\mathsf{T}} X (X^{\mathsf{T}} X )^{-1} X^{\mathsf{T}}
\end{equation}
\begin{equation}
= X (X^{\mathsf{T}} X )^{-1} X^{\mathsf{T}} = P.
\end{equation}
\end{proof}

\begin{proof}
\begin{equation}
(I_n - P)^2 = (I_n - P) (I_n - P)
\end{equation}
\begin{equation}
= I_n - P - P + P^2 = I_n - 2P + P = I_n - P.
\end{equation}
\end{proof}

\subsection{問2.8}
\begin{proof}
AICの定義は -2 (最大対数尤度) + 2 (自由パラメタの数) であり，第1項は
\begin{equation}
= -2 \left( - \frac{n}{2} \log (2 \pi \hat{\sigma}^2) - \frac{1}{2 \hat{\sigma}^2} (\bm{y} - X \bm{\beta})^{\mathsf{T}} (\bm{y} - X \bm{\beta}) \right).
\end{equation}
問2.3より$\sigma$の最尤推定量は$\hat{\sigma}^2 = \frac{1}{n} (\bm{y} - X \bm{\beta})^{\mathsf{T}} (\bm{y} - X \bm{\beta})$であることと，自由なパラメタの数は$\bm{\beta}$の次元$p+1$個と誤差分散$\hat{\sigma}^2$の合計$p+2$個なので
\begin{equation}
{\rm AIC} = n \log (2 \pi \hat{\sigma}^2) + n + 2(p + 2).
\end{equation}
\end{proof}

\end{document}